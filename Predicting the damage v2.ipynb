{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/datasets/rahul110/building-dataset-hackerearth-ml-6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  os.path.exists(PATH + 'full_train.csv') and os.path.exists(PATH + 'full_test.csv'):\n",
    "    \n",
    "    #check for the full train and test set\n",
    "    df_train = pd.read_csv(PATH + 'full_train.csv')\n",
    "    df_test = pd.read_csv(PATH + 'full_test.csv')\n",
    "    \n",
    "    df_train[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_test[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_train[\"count_families\"].fillna(1.0,inplace=True)\n",
    "else:\n",
    "    \n",
    "    # Load train and test data\n",
    "    df_train = pd.read_csv(PATH + 'train.csv')\n",
    "    df_test = pd.read_csv(PATH + 'test.csv')\n",
    "    df_struct = pd.read_csv(PATH + 'Building_Structure.csv')\n",
    "    df_own = pd.read_csv(PATH + 'Building_Ownership_Use.csv')\n",
    "\n",
    "    df_merge = pd.merge(df_struct,df_own,on=['building_id', 'district_id', 'vdcmun_id', 'ward_id'])\n",
    "    df_train = pd.merge(df_train,df_merge,on=['building_id', 'district_id', 'vdcmun_id'])\n",
    "    df_test  = pd.merge(df_test, df_merge, on =['building_id', 'district_id', 'vdcmun_id'])\n",
    "\n",
    "    del df_struct, df_own, df_merge\n",
    "\n",
    "    df_train.to_csv(PATH + 'full_train.csv',index=False)\n",
    "    df_test.to_csv(PATH + 'full_test.csv',index=False)\n",
    "    \n",
    "    df_train[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_test[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_train[\"count_families\"].fillna(1.0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_land_surface_condition(raw):\n",
    "    if raw.lower() != 'flat':\n",
    "        return \"slope\"\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_plan_configuration(raw):\n",
    "    if raw.lower() != 'rectangular':\n",
    "        return \"others\"\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_position(raw):\n",
    "    if raw.lower() != 'not attached':\n",
    "        return \"attached\"\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_ground_floor_type(raw):\n",
    "    if 'mud' in raw.lower():\n",
    "        return 'mud'\n",
    "    else:\n",
    "        return 'hard_floor'\n",
    "\n",
    "def clean_area_assesed(raw):\n",
    "    if raw.lower() == 'exterior' or raw.lower() == 'interior':\n",
    "        return 'visible'\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_foundation_type(raw):\n",
    "    if 'mud' in raw.lower():\n",
    "        return 'mud'\n",
    "    elif 'bamboo' in raw.lower():\n",
    "        return 'wooden'\n",
    "    else:\n",
    "        return 'cemented'\n",
    "\n",
    "def clean_roof_type(raw):\n",
    "    if 'light roof' in raw.lower():\n",
    "        return 'light roof'\n",
    "    elif 'heavy roof' in raw.lower():\n",
    "        return 'heavy roof'\n",
    "    else:\n",
    "        return 'rcc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [df_train, df_test]\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dataset.land_surface_condition = dataset.land_surface_condition.apply(clean_land_surface_condition)\n",
    "\n",
    "    dataset.plan_configuration = dataset.plan_configuration.apply(clean_plan_configuration)\n",
    "\n",
    "    dataset.position = dataset.position.apply(clean_position)\n",
    "\n",
    "    dataset.ground_floor_type = dataset.ground_floor_type.apply(clean_ground_floor_type)\n",
    "\n",
    "    dataset.area_assesed = dataset.area_assesed.apply(clean_area_assesed)\n",
    "\n",
    "    dataset.foundation_type = dataset.foundation_type.apply(clean_foundation_type)\n",
    "\n",
    "    dataset.roof_type = dataset.roof_type.apply(clean_roof_type)\n",
    "\n",
    "    dataset['isBuildingOld'] = (dataset.age_building > 30).astype('int')\n",
    "\n",
    "    dataset['isFloorRemoved'] = ((dataset['count_floors_pre_eq']-dataset['count_floors_post_eq']) > 0 ).astype('int')\n",
    "\n",
    "    dataset['isHeightChanged'] = ((dataset.height_ft_pre_eq - dataset.height_ft_post_eq) > 0 ).astype('int')\n",
    "    \n",
    "    dataset['isBuildingRemoved'] = (dataset.count_floors_post_eq == 0).astype('int')\n",
    "        \n",
    "    #dataset['height_per_floor_pre_eq'] = dataset.height_ft_pre_eq / dataset.count_floors_pre_eq\n",
    "    \n",
    "    dataset['volume_per_floor_pre_eq'] = np.log(dataset.plinth_area_sq_ft * (dataset.height_ft_pre_eq / dataset.count_floors_pre_eq))\n",
    "    \n",
    "    dataset['volume_per_floor_post_eq'] = ((dataset.height_ft_post_eq + 1) / (dataset.count_floors_post_eq + 1) * dataset.plinth_area_sq_ft).apply(np.log)\n",
    "    #dataset.plinth_area_sq_ft = dataset.plinth_area_sq_ft.apply(lambda x : np.log(x))\n",
    "     \n",
    "    dataset['isResidential'] = (dataset.count_families > 0).astype('int')\n",
    "    \n",
    "    dataset.age_building = dataset.age_building.apply(lambda x : np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_drop = ['has_geotechnical_risk_fault_crack', 'has_geotechnical_risk_flood',\n",
    "#                'has_geotechnical_risk_land_settlement', 'has_geotechnical_risk_landslide',\n",
    "#                'has_geotechnical_risk_liquefaction', 'has_geotechnical_risk_other', \n",
    "#                'has_geotechnical_risk_rock_fall','has_secondary_use_agriculture',\n",
    "#                'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
    "#                'has_secondary_use_institution', 'has_secondary_use_school',\n",
    "#                'has_secondary_use_industry', 'has_secondary_use_health_post',\n",
    "#                'has_secondary_use_gov_office', 'has_secondary_use_use_police',\n",
    "#                'has_secondary_use_other','legal_ownership_status','age_building',\n",
    "#                'count_floors_pre_eq','count_floors_post_eq','height_ft_pre_eq','height_ft_post_eq',\n",
    "#                'has_superstructure_adobe_mud', 'has_superstructure_stone_flag', \n",
    "#                'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', \n",
    "#                'has_superstructure_cement_mortar_brick', 'has_superstructure_other',\n",
    "#                'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "#                'has_superstructure_rc_engineered']\n",
    "\n",
    "#df_train.drop(columns=cols_to_drop,inplace=True,axis=1)\n",
    "#df_test.drop(columns=cols_to_drop,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['count_floors_pre_eq','count_floors_post_eq','height_ft_pre_eq','height_ft_post_eq', 'plinth_area_sq_ft']\n",
    "\n",
    "df_train.drop(columns=cols_to_drop,inplace=True,axis=1)\n",
    "df_test.drop(columns=cols_to_drop,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns.tolist():\n",
    "    if col != 'building_id':\n",
    "        if df_train[col].dtype == 'object':\n",
    "            sns.countplot(y=col,data=df_train)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.xlabel(col)\n",
    "            plt.hist(x=col,data=df_train)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_encode = [\"area_assesed\",\"foundation_type\", \"land_surface_condition\",\"roof_type\",'legal_ownership_status',\n",
    "                      \"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\",\"condition_post_eq\"]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for feature in features_to_encode:\n",
    "    #df_train[feature] = df_train[feature].astype('category').cat.codes\n",
    "    le = LabelEncoder().fit(df_train[feature])\n",
    "    df_train[feature] = le.transform(df_train[feature])                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['condition_post_eq_Covered by landslide'],inplace=True,axis=1)\n",
    "df_test.drop(columns=['condition_post_eq_Covered by landslide'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = df_train.damage_grade\n",
    "le = LabelEncoder().fit(target)\n",
    "\n",
    "Y = le.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['building_id','damage_grade'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds,dtrain):\n",
    "    \n",
    "    labels = dtrain.get_label()\n",
    "    \n",
    "    pred_label = np.argmax(preds, axis=1)\n",
    "    \n",
    "    f1 = f1_score(labels,pred_label,average='weighted')\n",
    "    \n",
    "    return 'f1_score',f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 10,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 5,\n",
    "    'subsample' : 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'seed':3,\n",
    "    #'predictor':'gpu_predictor',\n",
    "    'lambda':10}  # the number of classes that exist in this datset\n",
    "num_round = 1000  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    watchlist  = [(dtest,'test'), (dtrain,'train')]\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist, early_stopping_rounds=100,feval=compute_f1)\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(X_train, y_train, X_val, y_val, X_test):\n",
    "\n",
    "    bst = train_xgb(X.iloc[train_index].values, Y[train_index], X.iloc[test_index].values, Y[test_index])\n",
    "    \n",
    "    bst.save_model('mymodel')\n",
    "    #bst = xgb.Booster(param)\n",
    "    bst.load_model('mymodel')\n",
    "    \n",
    "    #xgboost issue : https://github.com/dmlc/xgboost/issues/1238\n",
    "    \n",
    "    dpredict = xgb.DMatrix(X_test)\n",
    "    pred = bst.predict(dpredict)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import KFold\n",
    "#kf = KFold(n_splits=3, shuffle=True, random_state=3)\n",
    "\n",
    "#models= []\n",
    "#for train_index, test_index in kf.split(df_train):    \n",
    "#    print(\"Split\")\n",
    "#    model = train_xgb(X.iloc[train_index].values, Y[train_index], X.iloc[test_index].values, Y[test_index])\n",
    "#    models.append(model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['building_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split\n",
      "[0]\ttest-merror:0.277657\ttrain-merror:0.273554\ttest-f1_score:0.724256\ttrain-f1_score:0.728206\n",
      "Multiple eval metrics have been passed: 'train-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until train-f1_score hasn't improved in 100 rounds.\n",
      "[1]\ttest-merror:0.275007\ttrain-merror:0.270679\ttest-f1_score:0.726384\ttrain-f1_score:0.730596\n",
      "[2]\ttest-merror:0.273288\ttrain-merror:0.269202\ttest-f1_score:0.72787\ttrain-f1_score:0.731845\n",
      "[3]\ttest-merror:0.272761\ttrain-merror:0.267956\ttest-f1_score:0.728268\ttrain-f1_score:0.733035\n",
      "[4]\ttest-merror:0.271707\ttrain-merror:0.266534\ttest-f1_score:0.729421\ttrain-f1_score:0.734558\n",
      "[5]\ttest-merror:0.270848\ttrain-merror:0.265591\ttest-f1_score:0.730465\ttrain-f1_score:0.735674\n",
      "[6]\ttest-merror:0.270302\ttrain-merror:0.264822\ttest-f1_score:0.731173\ttrain-f1_score:0.736637\n",
      "[7]\ttest-merror:0.269086\ttrain-merror:0.263214\ttest-f1_score:0.732392\ttrain-f1_score:0.738259\n",
      "[8]\ttest-merror:0.267799\ttrain-merror:0.261476\ttest-f1_score:0.733746\ttrain-f1_score:0.740045\n",
      "[9]\ttest-merror:0.266332\ttrain-merror:0.259563\ttest-f1_score:0.735138\ttrain-f1_score:0.741924\n",
      "[10]\ttest-merror:0.26505\ttrain-merror:0.257433\ttest-f1_score:0.736335\ttrain-f1_score:0.743969\n",
      "[11]\ttest-merror:0.263972\ttrain-merror:0.25622\ttest-f1_score:0.73725\ttrain-f1_score:0.744982\n",
      "[12]\ttest-merror:0.263103\ttrain-merror:0.254567\ttest-f1_score:0.738039\ttrain-f1_score:0.746539\n",
      "[13]\ttest-merror:0.262238\ttrain-merror:0.25323\ttest-f1_score:0.738818\ttrain-f1_score:0.747797\n",
      "[14]\ttest-merror:0.260928\ttrain-merror:0.251846\ttest-f1_score:0.740165\ttrain-f1_score:0.749212\n",
      "[15]\ttest-merror:0.259926\ttrain-merror:0.249987\ttest-f1_score:0.741177\ttrain-f1_score:0.75108\n",
      "[16]\ttest-merror:0.259707\ttrain-merror:0.249087\ttest-f1_score:0.741446\ttrain-f1_score:0.752018\n",
      "[17]\ttest-merror:0.258724\ttrain-merror:0.247558\ttest-f1_score:0.74242\ttrain-f1_score:0.753495\n",
      "[18]\ttest-merror:0.258354\ttrain-merror:0.246599\ttest-f1_score:0.742893\ttrain-f1_score:0.754519\n",
      "[19]\ttest-merror:0.25786\ttrain-merror:0.245438\ttest-f1_score:0.743364\ttrain-f1_score:0.755673\n",
      "[20]\ttest-merror:0.256583\ttrain-merror:0.243845\ttest-f1_score:0.744768\ttrain-f1_score:0.757336\n",
      "[21]\ttest-merror:0.255495\ttrain-merror:0.242251\ttest-f1_score:0.745794\ttrain-f1_score:0.758875\n",
      "[22]\ttest-merror:0.255111\ttrain-merror:0.241539\ttest-f1_score:0.746121\ttrain-f1_score:0.759522\n",
      "[23]\ttest-merror:0.254284\ttrain-merror:0.240153\ttest-f1_score:0.746839\ttrain-f1_score:0.760809\n",
      "[24]\ttest-merror:0.253534\ttrain-merror:0.239063\ttest-f1_score:0.747651\ttrain-f1_score:0.761957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=3)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for train_index, test_index in kf.split(df_train):    \n",
    "    print(\"Split\")\n",
    "    pred = train_and_predict(X.iloc[train_index].values, Y[train_index], X.iloc[test_index].values, Y[test_index],X_test)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'building_id' : df_test['building_id'],\n",
    "    'damage_grade' : test_preds.astype(int)\n",
    "})\n",
    "\n",
    "submission.damage_grade = submission.damage_grade.apply(lambda x : \"Grade \" + str(x+1) )\n",
    "\n",
    "submission.to_csv('final_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.damage_grade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area_assesed', 'building_id', 'damage_grade', 'district_id',\n",
       "       'has_geotechnical_risk', 'has_geotechnical_risk_fault_crack',\n",
       "       'has_geotechnical_risk_flood', 'has_geotechnical_risk_land_settlement',\n",
       "       'has_geotechnical_risk_landslide', 'has_geotechnical_risk_liquefaction',\n",
       "       'has_geotechnical_risk_other', 'has_geotechnical_risk_rock_fall',\n",
       "       'has_repair_started', 'vdcmun_id', 'ward_id', 'count_floors_pre_eq',\n",
       "       'count_floors_post_eq', 'age_building', 'plinth_area_sq_ft',\n",
       "       'height_ft_pre_eq', 'height_ft_post_eq', 'land_surface_condition',\n",
       "       'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type',\n",
       "       'position', 'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'condition_post_eq', 'legal_ownership_status', 'count_families',\n",
       "       'has_secondary_use', 'has_secondary_use_agriculture',\n",
       "       'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
       "       'has_secondary_use_institution', 'has_secondary_use_school',\n",
       "       'has_secondary_use_industry', 'has_secondary_use_health_post',\n",
       "       'has_secondary_use_gov_office', 'has_secondary_use_use_police',\n",
       "       'has_secondary_use_other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
