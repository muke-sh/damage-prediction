{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/datasets/rahul110/building-dataset-hackerearth-ml-6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  os.path.exists(PATH + 'full_train.csv') and os.path.exists(PATH + 'full_test.csv'):\n",
    "    \n",
    "    #check for the full train and test set\n",
    "    df_train = pd.read_csv(PATH + 'full_train.csv')\n",
    "    df_test = pd.read_csv(PATH + 'full_test.csv')\n",
    "    \n",
    "    df_train[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_test[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_train[\"count_families\"].fillna(1.0,inplace=True)\n",
    "else:\n",
    "    \n",
    "    # Load train and test data\n",
    "    df_train = pd.read_csv(PATH + 'train.csv')\n",
    "    df_test = pd.read_csv(PATH + 'test.csv')\n",
    "    df_struct = pd.read_csv(PATH + 'Building_Structure.csv')\n",
    "    df_own = pd.read_csv(PATH + 'Building_Ownership_Use.csv')\n",
    "\n",
    "    df_merge = pd.merge(df_struct,df_own,on=['building_id', 'district_id', 'vdcmun_id', 'ward_id'])\n",
    "    df_train = pd.merge(df_train,df_merge,on=['building_id', 'district_id', 'vdcmun_id'])\n",
    "    df_test  = pd.merge(df_test, df_merge, on =['building_id', 'district_id', 'vdcmun_id'])\n",
    "\n",
    "    del df_struct, df_own, df_merge\n",
    "\n",
    "    df_train.to_csv(PATH + 'full_train.csv',index=False)\n",
    "    df_test.to_csv(PATH + 'full_test.csv',index=False)\n",
    "    \n",
    "    df_train[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_test[\"has_repair_started\"].fillna(0.0,inplace=True)\n",
    "    df_train[\"count_families\"].fillna(1.0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_land_surface_condition(raw):\n",
    "    if raw.lower() != 'flat':\n",
    "        return \"slope\"\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_plan_configuration(raw):\n",
    "    if raw.lower() != 'rectangular':\n",
    "        return \"others\"\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_position(raw):\n",
    "    if raw.lower() != 'not attached':\n",
    "        return \"attached\"\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_ground_floor_type(raw):\n",
    "    if 'mud' in raw.lower():\n",
    "        return 'mud'\n",
    "    else:\n",
    "        return 'hard_floor'\n",
    "\n",
    "def clean_area_assesed(raw):\n",
    "    if raw.lower() == 'exterior' or raw.lower() == 'interior':\n",
    "        return 'visible'\n",
    "    else:\n",
    "        return raw.lower()\n",
    "\n",
    "def clean_foundation_type(raw):\n",
    "    if 'mud' in raw.lower():\n",
    "        return 'mud'\n",
    "    elif 'bamboo' in raw.lower():\n",
    "        return 'wooden'\n",
    "    else:\n",
    "        return 'cemented'\n",
    "\n",
    "def clean_roof_type(raw):\n",
    "    if 'light roof' in raw.lower():\n",
    "        return 'light roof'\n",
    "    elif 'heavy roof' in raw.lower():\n",
    "        return 'heavy roof'\n",
    "    else:\n",
    "        return 'rcc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [df_train, df_test]\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    dataset.land_surface_condition = dataset.land_surface_condition.apply(clean_land_surface_condition)\n",
    "\n",
    "    dataset.plan_configuration = dataset.plan_configuration.apply(clean_plan_configuration)\n",
    "\n",
    "    dataset.position = dataset.position.apply(clean_position)\n",
    "\n",
    "    dataset.ground_floor_type = dataset.ground_floor_type.apply(clean_ground_floor_type)\n",
    "\n",
    "    dataset.area_assesed = dataset.area_assesed.apply(clean_area_assesed)\n",
    "\n",
    "    dataset.foundation_type = dataset.foundation_type.apply(clean_foundation_type)\n",
    "\n",
    "    dataset.roof_type = dataset.roof_type.apply(clean_roof_type)\n",
    "\n",
    "    dataset['isBuildingOld'] = (dataset.age_building > 30).astype('int')\n",
    "\n",
    "    dataset['isFloorRemoved'] = ((dataset['count_floors_pre_eq']-dataset['count_floors_post_eq']) > 0 ).astype('int')\n",
    "\n",
    "    dataset['isHeightChanged'] = ((dataset.height_ft_pre_eq - dataset.height_ft_post_eq) > 0 ).astype('int')\n",
    "    \n",
    "    dataset['isBuildingRemoved'] = (dataset.count_floors_post_eq == 0).astype('int')\n",
    "        \n",
    "    #dataset['height_per_floor_pre_eq'] = dataset.height_ft_pre_eq / dataset.count_floors_pre_eq\n",
    "    \n",
    "    dataset['volume_per_floor_pre_eq'] = np.log(dataset.plinth_area_sq_ft * (dataset.height_ft_pre_eq / dataset.count_floors_pre_eq))\n",
    "    \n",
    "    dataset['volume_per_floor_post_eq'] = ((dataset.height_ft_post_eq + 1) / (dataset.count_floors_post_eq + 1) * dataset.plinth_area_sq_ft).apply(np.log)\n",
    "    #dataset.plinth_area_sq_ft = dataset.plinth_area_sq_ft.apply(lambda x : np.log(x))\n",
    "     \n",
    "    dataset['isResidential'] = (dataset.count_families > 0).astype('int')\n",
    "    \n",
    "    dataset.age_building = dataset.age_building.apply(lambda x : np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_drop = ['has_geotechnical_risk_fault_crack', 'has_geotechnical_risk_flood',\n",
    "#                'has_geotechnical_risk_land_settlement', 'has_geotechnical_risk_landslide',\n",
    "#                'has_geotechnical_risk_liquefaction', 'has_geotechnical_risk_other', \n",
    "#                'has_geotechnical_risk_rock_fall','has_secondary_use_agriculture',\n",
    "#                'has_secondary_use_hotel', 'has_secondary_use_rental',\n",
    "#                'has_secondary_use_institution', 'has_secondary_use_school',\n",
    "#                'has_secondary_use_industry', 'has_secondary_use_health_post',\n",
    "#                'has_secondary_use_gov_office', 'has_secondary_use_use_police',\n",
    "#                'has_secondary_use_other','legal_ownership_status','age_building',\n",
    "#                'count_floors_pre_eq','count_floors_post_eq','height_ft_pre_eq','height_ft_post_eq',\n",
    "#                'has_superstructure_adobe_mud', 'has_superstructure_stone_flag', \n",
    "#                'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', \n",
    "#                'has_superstructure_cement_mortar_brick', 'has_superstructure_other',\n",
    "#                'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "#                'has_superstructure_rc_engineered']\n",
    "\n",
    "#df_train.drop(columns=cols_to_drop,inplace=True,axis=1)\n",
    "#df_test.drop(columns=cols_to_drop,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['count_floors_pre_eq','count_floors_post_eq','height_ft_pre_eq','height_ft_post_eq', 'plinth_area_sq_ft']\n",
    "\n",
    "df_train.drop(columns=cols_to_drop,inplace=True,axis=1)\n",
    "df_test.drop(columns=cols_to_drop,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns.tolist():\n",
    "    if col != 'building_id':\n",
    "        if df_train[col].dtype == 'object':\n",
    "            sns.countplot(y=col,data=df_train)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.xlabel(col)\n",
    "            plt.hist(x=col,data=df_train)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_encode = [\"area_assesed\",\"foundation_type\", \"land_surface_condition\",\"roof_type\",'legal_ownership_status',\n",
    "                      \"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\",\"condition_post_eq\"]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for dataset in datasets:\n",
    "    for feature in features_to_encode:\n",
    "        #df_train[feature] = df_train[feature].astype('category').cat.codes\n",
    "        le = LabelEncoder().fit(dataset[feature])\n",
    "        dataset[feature] = le.transform(dataset[feature])                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['condition_post_eq_Covered by landslide'],inplace=True,axis=1)\n",
    "df_test.drop(columns=['condition_post_eq_Covered by landslide'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = df_train.damage_grade\n",
    "le = LabelEncoder().fit(target)\n",
    "\n",
    "Y = le.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['building_id','damage_grade'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds,dtrain):\n",
    "    \n",
    "    labels = dtrain.get_label()\n",
    "    \n",
    "    pred_label = np.argmax(preds, axis=1)\n",
    "    \n",
    "    f1 = f1_score(labels,pred_label,average='weighted')\n",
    "    \n",
    "    return 'f1_score',f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 10,  # the maximum depth of each tree\n",
    "    'eta': 0.05,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 5,\n",
    "    'subsample' : 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'seed':3,\n",
    "    #'predictor':'gpu_predictor',\n",
    "    'lambda':10}  # the number of classes that exist in this datset\n",
    "num_round = 10  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    watchlist  = [(dtest,'test'), (dtrain,'train')]\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist, early_stopping_rounds=2,feval=compute_f1)\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(X_train, y_train, X_val, y_val, X_test):\n",
    "\n",
    "    bst = train_xgb(X.iloc[train_index].values, Y[train_index], X.iloc[test_index].values, Y[test_index])\n",
    "    \n",
    "    bst.save_model('mymodel')\n",
    "    bst = xgb.Booster(param)\n",
    "    bst.load_model('mymodel')\n",
    "    \n",
    "    #xgboost issue : https://github.com/dmlc/xgboost/issues/1238\n",
    "    \n",
    "    dpredict = xgb.DMatrix(X_test)\n",
    "    pred = bst.predict(dpredict)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import KFold\n",
    "#kf = KFold(n_splits=3, shuffle=True, random_state=3)\n",
    "\n",
    "#models= []\n",
    "#for train_index, test_index in kf.split(df_train):    \n",
    "#    print(\"Split\")\n",
    "#    model = train_xgb(X.iloc[train_index].values, Y[train_index], X.iloc[test_index].values, Y[test_index])\n",
    "#    models.append(model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['building_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split\n",
      "[0]\ttest-merror:0.311866\ttrain-merror:0.306386\ttest-f1_score:0.684526\ttrain-f1_score:0.689858\n",
      "Multiple eval metrics have been passed: 'train-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until train-f1_score hasn't improved in 2 rounds.\n",
      "[1]\ttest-merror:0.274585\ttrain-merror:0.270748\ttest-f1_score:0.722167\ttrain-f1_score:0.725852\n",
      "[2]\ttest-merror:0.27515\ttrain-merror:0.270518\ttest-f1_score:0.719045\ttrain-f1_score:0.723741\n",
      "Stopping. Best iteration:\n",
      "[0]\ttest-merror:0.311866\ttrain-merror:0.306386\ttest-f1_score:0.684526\ttrain-f1_score:0.689858\n",
      "\n",
      "Split\n",
      "[0]\ttest-merror:0.308015\ttrain-merror:0.304461\ttest-f1_score:0.691131\ttrain-f1_score:0.694471\n",
      "Multiple eval metrics have been passed: 'train-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until train-f1_score hasn't improved in 2 rounds.\n",
      "[1]\ttest-merror:0.275924\ttrain-merror:0.27227\ttest-f1_score:0.721153\ttrain-f1_score:0.724781\n",
      "[2]\ttest-merror:0.275634\ttrain-merror:0.272006\ttest-f1_score:0.719294\ttrain-f1_score:0.722882\n",
      "Stopping. Best iteration:\n",
      "[0]\ttest-merror:0.308015\ttrain-merror:0.304461\ttest-f1_score:0.691131\ttrain-f1_score:0.694471\n",
      "\n",
      "Split\n",
      "[0]\ttest-merror:0.308794\ttrain-merror:0.305506\ttest-f1_score:0.68678\ttrain-f1_score:0.690585\n",
      "Multiple eval metrics have been passed: 'train-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until train-f1_score hasn't improved in 2 rounds.\n",
      "[1]\ttest-merror:0.277173\ttrain-merror:0.271292\ttest-f1_score:0.718958\ttrain-f1_score:0.725313\n",
      "[2]\ttest-merror:0.276859\ttrain-merror:0.269915\ttest-f1_score:0.717241\ttrain-f1_score:0.724579\n",
      "Stopping. Best iteration:\n",
      "[0]\ttest-merror:0.308794\ttrain-merror:0.305506\ttest-f1_score:0.68678\ttrain-f1_score:0.690585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=3)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for train_index, test_index in kf.split(df_train):    \n",
    "    print(\"Split\")\n",
    "    pred = train_and_predict(X.iloc[train_index].values, Y[train_index], X.iloc[test_index].values, Y[test_index],X_test)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'building_id' : df_test['building_id'],\n",
    "    'damage_grade' : test_preds.astype(int)\n",
    "})\n",
    "\n",
    "submission.damage_grade = submission.damage_grade.apply(lambda x : \"Grade \" + str(x+1) )\n",
    "\n",
    "submission.to_csv('final_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.damage_grade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = (preds[0] + preds[1] + preds[2])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = np.argmax(avg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, ..., 0, 4, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
